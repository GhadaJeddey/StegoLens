{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# The Audio Model\n",
        "\n",
        "## Conversion from .g729a to .wav\n",
        "Since the dataset contains audio files in the .g729a format, they must be converted to .wav format.\n",
        "\n",
        "This code:\n",
        "\n",
        "\n",
        "*   Defines input folders for stego (positive) and non-stego (negative) audio files.\n",
        "*   Defines corresponding output folders for .wav conversions.\n",
        "*   Uses ffmpeg via Python's subprocess to convert .g729a files to .wav.\n",
        "*   Automatically creates output folders if they donâ€™t exist.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "co60krBoKjBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Paths to your dataset folders\n",
        "positive_folder = r'dataset/g729a_Steg'\n",
        "negative_folder = r'dataset/g729a_0'\n",
        "\n",
        "# Output folders\n",
        "positive_output = r'dataset/positive_wav'\n",
        "negative_output = r'dataset/negative_wav'\n",
        "\n",
        "# Create output folders if they don't exist\n",
        "os.makedirs(positive_output, exist_ok=True)\n",
        "os.makedirs(negative_output, exist_ok=True)\n",
        "\n",
        "def convert_to_wav(input_folder, output_folder):\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.g729a'):\n",
        "            input_path = os.path.join(input_folder, filename)\n",
        "            output_filename = os.path.splitext(filename)[0] + '.wav'\n",
        "            output_path = os.path.join(output_folder, output_filename)\n",
        "\n",
        "            # Command to run ffmpeg\n",
        "            command = ['ffmpeg', '-y', '-f', 'g729', '-i', input_path, output_path]\n",
        "\n",
        "            # Execute the command\n",
        "            subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "\n",
        "# Convert both positive and negative samples\n",
        "convert_to_wav(positive_folder, positive_output)\n",
        "convert_to_wav(negative_folder, negative_output)\n"
      ],
      "metadata": {
        "id": "1BfWTsEuLjfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the ffmpeg to convert all the files of the dataset to .wav and download the converted files to new folders."
      ],
      "metadata": {
        "id": "Axf_1VCJLw9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature extraction\n",
        "\n",
        "Once files are in .wav format, features that reflect the impact of steganographic embedding on audio signals are extracted.\n",
        "\n",
        "The extract_features function extracts MFCC, Spectral Centroid, Spectral Bandwidth, Spectral Flatness and Zero-Crossing Rate using the Librosa library.\n",
        "\n",
        "The extract_LPC_features extracts the LPC coefficients for each frame and extract their mean, variance and their differences delta.\n"
      ],
      "metadata": {
        "id": "Poi843pVMOXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.signal.windows import hamming\n",
        "from librosa import lpc\n",
        "import soundfile as sf\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "\n",
        "def extract_features(y,sr):\n",
        "\n",
        "\n",
        "    # MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "    # Spectral features\n",
        "    spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))\n",
        "    spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))\n",
        "    spectral_flatness = np.mean(librosa.feature.spectral_flatness(y=y))\n",
        "\n",
        "    # Zero-crossing rate\n",
        "    zero_crossings = np.mean(librosa.feature.zero_crossing_rate(y))\n",
        "\n",
        "    # Combine all features into one array\n",
        "    features = np.hstack([mfccs_mean, spectral_centroid, spectral_bandwidth, spectral_flatness, zero_crossings])\n",
        "\n",
        "    return features\n",
        "\n",
        "def extract_lpc_features(audio, sr, frame_length=0.05, frame_shift=0.01, order=10, min_duration=0.2):\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Duration check\n",
        "        duration = len(audio) / sr\n",
        "        if duration < min_duration:\n",
        "            print(f\"Skipped (too short): {audio}\")\n",
        "            return None\n",
        "\n",
        "        frame_size = int(frame_length * sr)\n",
        "        hop_size = int(frame_shift * sr)\n",
        "        num_frames = 1 + (len(audio) - frame_size) // hop_size\n",
        "\n",
        "        lpcs = []\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            start = i * hop_size\n",
        "            frame = audio[start:start + frame_size]\n",
        "            if len(frame) < frame_size:\n",
        "                break\n",
        "            frame *= hamming(len(frame))\n",
        "            frame = frame / (np.max(np.abs(frame)) + 1e-6)\n",
        "\n",
        "            try:\n",
        "                a = lpc(frame, order=order)\n",
        "                #print(\"LPC coeffs:\", a)\n",
        "                if len(a) == order + 1:  # LPC includes a0=1\n",
        "                    lpcs.append(a[1:])  # Skip the first coeff (it's always 1)\n",
        "            except Exception as e:\n",
        "                print(f\"Skipped unstable frame: {e}\")\n",
        "                continue\n",
        "\n",
        "        lpcs = np.array(lpcs)\n",
        "        if len(lpcs) == 0:\n",
        "            return None\n",
        "\n",
        "        # Compute mean, variance, and delta of LPCs\n",
        "        mean_lpc = np.mean(lpcs, axis=0)\n",
        "        var_lpc = np.var(lpcs, axis=0)\n",
        "        delta_lpc = np.mean(np.abs(np.diff(lpcs, axis=0)), axis=0)\n",
        "\n",
        "        features = np.concatenate([mean_lpc, var_lpc, delta_lpc])\n",
        "        return features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {audio}: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "50qnsXKmMd5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once individual feature extraction functions are ready, the entire dataset (positive and negative samples) is processed to extract features and compile them into a structured .csv file for model training.\n",
        "\n",
        "Since the dataset seperates the negative and positive samples in different folder we need to assign a label for each file (0 for clean and 1 for stego) for the combined csv file."
      ],
      "metadata": {
        "id": "QuDy5Vl5Mg3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_folder(folder_path, output_csv, label=None):\n",
        "\n",
        "    data = []\n",
        "    for file in tqdm(os.listdir(folder_path)):\n",
        "        if file.lower().endswith(\".wav\"):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            try:\n",
        "                audio, sr = sf.read(file_path)\n",
        "                if len(audio.shape) > 1:  # Convert stereo to mono\n",
        "                    audio = audio[:, 0]\n",
        "\n",
        "                lpc_features = extract_lpc_features(audio, sr)\n",
        "                basic_features = extract_features(audio, sr)\n",
        "\n",
        "                features = np.concatenate([basic_features, lpc_features] )\n",
        "\n",
        "                if features is not None:\n",
        "                    row = list(features)\n",
        "                    if label is not None:\n",
        "                        row.append(label)\n",
        "                    data.append(row)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file}: {e}\")\n",
        "\n",
        "    if not data:\n",
        "        print(f\"No features extracted from folder: {folder_path}\")\n",
        "        return\n",
        "\n",
        "    if data:\n",
        "        columns =[f\"mfcc_{i+1}\" for i in range(13)] + \\\n",
        "              [\"spectral_centroid\", \"spectral_bandwidth\", \"spectral_flatness\", \"zero_crossing_rate\"] + \\\n",
        "              [f\"mean_lpc_{i}\" for i in range(10)] + \\\n",
        "              [f\"var_lpc_{i}\" for i in range(10)] + \\\n",
        "              [f\"delta_lpc_{i}\" for i in range(10)]+ ['label']\n",
        "        df = pd.DataFrame(data, columns=columns)\n",
        "        df.to_csv(output_csv, index=False)\n",
        "        print(f\"Saved features to {output_csv}\")\n",
        "\n",
        "\n",
        "''' The code execution for the feature extraction for the full dataset\n",
        "clean_folder = \"dataset\\\\negative_wav\"\n",
        "stego_folder = \"dataset\\\\positive_wav\"\n",
        "\n",
        "process_folder(clean_folder, \"dataset\\\\clean_features.csv\", label=0)\n",
        "process_folder(stego_folder, \"dataset\\\\stego_features.csv\", label=1)\n",
        "\n",
        "#Merging the two .csv files\n",
        "\n",
        "df_clean = pd.read_csv(\"dataset\\\\clean_features.csv\")\n",
        "df_stego = pd.read_csv(\"dataset\\\\stego_features.csv\")\n",
        "df_all = pd.concat([df_clean, df_stego], ignore_index=True)\n",
        "df_all.to_csv(\"dataset\\\\combined_features.csv\", index=False)\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "2j0mBJtLNGFv",
        "outputId": "b43d20bc-d3a3-4e61-fdab-8435d49e00aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The code execution for the feature extraction for the full dataset \\nclean_folder = \"dataset\\\\negative_wav\"\\nstego_folder = \"dataset\\\\positive_wav\"\\n\\nprocess_folder(clean_folder, \"dataset\\\\clean_features.csv\", label=0)\\nprocess_folder(stego_folder, \"dataset\\\\stego_features.csv\", label=1)\\n\\n#Merging the two .csv files \\n\\ndf_clean = pd.read_csv(\"dataset\\\\clean_features.csv\")\\ndf_stego = pd.read_csv(\"dataset\\\\stego_features.csv\")\\ndf_all = pd.concat([df_clean, df_stego], ignore_index=True)\\ndf_all.to_csv(\"dataset\\\\combined_features.csv\", index=False)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract_features_file returns the features for only one file."
      ],
      "metadata": {
        "id": "Fd9Ylh_7NG4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features_file(audio,sr):\n",
        "\n",
        "    lpc_feature = extract_lpc_features(audio,sr)\n",
        "    basic_features = extract_features(audio,sr)\n",
        "    features = np.concatenate([basic_features, lpc_feature])\n",
        "    return(features)"
      ],
      "metadata": {
        "id": "HaQTXFYQNYUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "\n",
        "The model_learning.py trains a xgboost model from the saved combined_features.csv which contains the features for all the files in the dataset and that contains the appropriate labels. ( 0 for clean and 1 for stego)"
      ],
      "metadata": {
        "id": "cG_lDuqjNacm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "\n",
        "#loading the csv file\n",
        "csv_file = pd.read_csv('dataset//combined_features.csv')\n",
        "\n",
        "# Seperate the labels from the features\n",
        "label = csv_file['label']\n",
        "features = csv_file.drop(columns=['label'])\n",
        "\n",
        "\n",
        "\n",
        "#divide the training set and the learning set\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, label, test_size=0.2, random_state=42)\n",
        "\n",
        "#training the model\n",
        "model = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "print('training the model ...')\n",
        "model.fit(x_train, y_train)\n",
        "print(\"model trained\")"
      ],
      "metadata": {
        "id": "K4NOircCN_n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to test the model we print its accuracy, a full classification report and plot the confusion matrix"
      ],
      "metadata": {
        "id": "L5b-WYaQOC-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prediction\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Accuracy\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Full classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Clean\", \"Stego\"], yticklabels=[\"Clean\", \"Stego\"])\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "hf-Bk-hxOWXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We saved the model as a .pkl file"
      ],
      "metadata": {
        "id": "TB8FFZHDOZUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(model,\"audio_detection_model.pkl\")"
      ],
      "metadata": {
        "id": "duLNmJM9OffG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Prediction Model\n",
        "To run test the model with a new audio file we run this code that firslt checks if the file is a .wav file and extract its features and checks if the file is stego or clean."
      ],
      "metadata": {
        "id": "-UoZGaV7Oh0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import numpy as np\n",
        "from feature_extraction import extract_features_file # same one as before\n",
        "import os\n",
        "\n",
        "# Load saved model and scaler\n",
        "model = joblib.load(\"audio_detection_model.pkl\")\n",
        "\n",
        "\n",
        "# Predict function\n",
        "def predict(file_path):\n",
        "\n",
        "    if not file_path.lower().endswith(\".wav\"):\n",
        "        print(f\"Unsupported file type: {file_path}. Only .wav files are supported.\")\n",
        "        return\n",
        "\n",
        "    features = extract_features_file(file_path)\n",
        "    if features is None:\n",
        "        print(\"Could not extract features.\")\n",
        "        return\n",
        "    features = features.reshape(1, -1)\n",
        "    prediction = model.predict(features)\n",
        "    print(f\"Prediction for {file_path}: {'STEGANOGRAPHIC' if prediction == 1 else 'CLEAN'}\")"
      ],
      "metadata": {
        "id": "qGECAycjPtb2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}