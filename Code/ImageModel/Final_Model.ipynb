{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "zg_6q7SDfw5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Custom PyTorch Dataset class for Steganography Image Classification\n",
        "class StegoDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, base_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Initializes the dataset by loading paths to all images and assigning labels.\n",
        "\n",
        "        Args:\n",
        "            base_dir (string): Root directory containing:\n",
        "                - 'cover/' folder for clean images (label 0)\n",
        "                - 'stego/LSB/', 'stego/WOW/', 'stego/HILL/' for stego images (labels 1, 2, 3)\n",
        "            transform (callable, optional): Transformations to apply to each image (e.g., resizing, normalization).\n",
        "        \"\"\"\n",
        "        self.transform = transform\n",
        "        self.data = []  # Will store tuples of (image_path, label)\n",
        "\n",
        "        # Define class names, directory paths, and associated labels\n",
        "        self.class_dict = {\n",
        "            'cover': (os.path.join(base_dir, 'cover'), 0),             # Label 0 for clean images\n",
        "            'lsb': (os.path.join(base_dir, 'stego', 'LSB'), 1),        # Label 1 for LSB stego images\n",
        "            'wow': (os.path.join(base_dir, 'stego', 'WOW'), 2),        # Label 2 for WOW stego images\n",
        "            'hill': (os.path.join(base_dir, 'stego', 'HILL'), 3)       # Label 3 for HILL stego images\n",
        "        }\n",
        "\n",
        "        # Iterate over each class directory to collect image paths and corresponding labels\n",
        "        for class_name, (class_dir, label) in self.class_dict.items():\n",
        "            if not os.path.exists(class_dir):\n",
        "                # Print a warning if the expected subdirectory is missing\n",
        "                print(f\"[WARNING] Missing directory: {class_dir}\")\n",
        "                continue\n",
        "            for img_file in sorted(os.listdir(class_dir)):\n",
        "                # Include only supported image formats\n",
        "                if img_file.endswith(('.pgm', '.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                    img_path = os.path.join(class_dir, img_file)\n",
        "                    self.data.append((img_path, label))  # Append (image_path, label) to dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the total number of image samples in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Loads and returns a sample (image, label) at the specified index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sample to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (image_tensor, label) where image_tensor is a transformed image.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            img_path, label = self.data[idx]  # Get image path and class label\n",
        "            img = Image.open(img_path)        # Open image using PIL\n",
        "\n",
        "            # Convert to grayscale if image is not already in 'L' mode\n",
        "            if img.mode != 'L':\n",
        "                img = img.convert('L')\n",
        "\n",
        "            # Apply transformations (e.g., resizing, tensor conversion, normalization)\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "\n",
        "            return img, label  # Return processed image and label\n",
        "        except Exception as e:\n",
        "            # Print detailed error if image fails to load\n",
        "            print(f\"Error loading idx={idx}: {e}\")\n",
        "            raise e  # Re-raise exception to halt DataLoader or debugging\n"
      ],
      "metadata": {
        "id": "eSd0DsQCSO-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# Mount Google Drive to access datasets stored in your Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# -------------------------------\n",
        "# Define Image Transform Pipelines\n",
        "# -------------------------------\n",
        "\n",
        "# Transformations for training set (with data augmentation)\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Transformations for validation and test sets (no augmentation)\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),              # Resize to 256x256\n",
        "    transforms.ToTensor(),                      # Convert to tensor\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5]) # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# -------------------------------\n",
        "# Load Dataset\n",
        "# -------------------------------\n",
        "\n",
        "# Root directory where dataset folders ('cover', 'stego/LSB', etc.) are stored\n",
        "base_path = '/content/drive/MyDrive/Stego-Images-Dataset'\n",
        "\n",
        "# Initialize the custom dataset without transform\n",
        "dataset = StegoDataset(base_path)\n",
        "\n",
        "# Define split proportions\n",
        "train_size = int(0.7 * len(dataset))  # 70% for training\n",
        "val_size = int(0.15 * len(dataset))   # 15% for validation\n",
        "test_size = len(dataset) - train_size - val_size  # Remaining 15% for testing\n",
        "\n",
        "# Perform random split with fixed seed for reproducibility\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "\n",
        "\n",
        "# Set the appropriate transform for each subset\n",
        "train_dataset.dataset.transform = train_transforms\n",
        "val_dataset.dataset.transform = val_test_transforms\n",
        "test_dataset.dataset.transform = val_test_transforms\n",
        "\n",
        "# -------------------------------\n",
        "# Prepare Data Loaders\n",
        "# -------------------------------\n",
        "\n",
        "batch_size = 32  # Number of samples per batch\n",
        "\n",
        "# DataLoader for training\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,               # Shuffle data for better generalization\n",
        "    num_workers=2,              # Number of parallel data loading workers\n",
        "    pin_memory=True,            # Speed up data transfer to GPU\n",
        "    persistent_workers=True     # Keep workers alive between epochs\n",
        ")\n",
        "\n",
        "# DataLoader for validation (no shuffling)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "# DataLoader for test (no shuffling)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "\n",
        "# Use CUDA (GPU) if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "JogqoRBpXKkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet34 Model"
      ],
      "metadata": {
        "id": "apH8XXByPhqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load pretrained ResNet34 (ImageNet weights)\n",
        "model = models.resnet34(weights='ResNet34_Weights.IMAGENET1K_V1')\n",
        "\n",
        "# Adapt the first convolution layer to accept grayscale input (1 channel)\n",
        "original_first_conv = model.conv1\n",
        "new_first_conv = nn.Conv2d(\n",
        "    in_channels=1,              # Grayscale input\n",
        "    out_channels=64,            # Match original ResNet34\n",
        "    kernel_size=7,\n",
        "    stride=2,\n",
        "    padding=3,\n",
        "    bias=False\n",
        ")\n",
        "\n",
        "# Initialize the grayscale conv weights by averaging across RGB channels\n",
        "if original_first_conv.weight is not None:\n",
        "    new_first_conv.weight.data = original_first_conv.weight.data.mean(dim=1, keepdim=True)\n",
        "    # Apply Kaiming normalization (better for ReLU activation)\n",
        "    nn.init.kaiming_normal_(new_first_conv.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "# Replace the original conv1 with the new grayscale version\n",
        "model.conv1 = new_first_conv\n",
        "\n",
        "# -----------------------------------------------\n",
        "#  Modify the Final Classification Head\n",
        "# -----------------------------------------------\n",
        "num_classes = 4  # Steganography detection: Cover, LSB, WOW, HILL\n",
        "\n",
        "# Replace the fully connected layer with a custom head\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.5),                            # High dropout to reduce overfitting\n",
        "    nn.Linear(model.fc.in_features, 256),      # Reduce to intermediate dimension\n",
        "    nn.BatchNorm1d(256),                        # Normalize for better training\n",
        "    nn.LeakyReLU(0.1, inplace=True),            # More robust than ReLU for sparse gradients\n",
        "    nn.Dropout(0.3),                            # Additional regularization\n",
        "    nn.Linear(256, num_classes, bias=False)     # No bias needed (handled by BatchNorm)\n",
        ")\n",
        "\n",
        "# -----------------------------------------------\n",
        "#  Initialize Classifier Weights\n",
        "# -----------------------------------------------\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        nn.init.normal_(m.weight, mean=0.0, std=0.01)  # Small std for stable learning\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        nn.init.constant_(m.weight, 1)                 # Start with identity scaling\n",
        "        nn.init.constant_(m.bias, 0)                   # No initial shift\n",
        "\n",
        "# Apply the custom initialization to the classifier\n",
        "model.fc.apply(init_weights)\n",
        "\n",
        "# -----------------------------------------------\n",
        "# Wrap Model with LogitScaler\n",
        "# -----------------------------------------------\n",
        "\n",
        "# LogitScaler scales the output logits to stabilize training, especially helpful in steganalysis with subtle feature differences.\n",
        "class LogitScaler(nn.Module):\n",
        "    def __init__(self, model, scale=0.5):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.scale = scale\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x) * self.scale  # Scale the logits (before softmax or loss)\n",
        "\n",
        "model = LogitScaler(model).to(device)\n"
      ],
      "metadata": {
        "id": "KsPFJTnnBlNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training  and Evaluating Functions"
      ],
      "metadata": {
        "id": "oJrq6-lRdoA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, roc_auc_score, cohen_kappa_score,\n",
        "    confusion_matrix, classification_report, precision_score, recall_score\n",
        ")\n",
        "import psutil\n",
        "import time\n",
        "\n",
        "# ---------------------------------------\n",
        "# Utility: Format Seconds into MM:SS\n",
        "# ---------------------------------------\n",
        "def format_time(seconds):\n",
        "    mins = int(seconds // 60)\n",
        "    secs = int(seconds % 60)\n",
        "    return f\"{mins}m {secs}s\"\n",
        "\n",
        "# ---------------------------------------\n",
        "# Model Training Function\n",
        "# ---------------------------------------\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
        "                num_epochs=10, checkpoint_path='best_model.pth', device='cuda', patience=5):\n",
        "    print(f\"Training device: {device}\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Training history tracking\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'val_metrics': [],\n",
        "        'best_epoch': 0,\n",
        "        'class_names': ['Cover', 'LSB', 'WOW', 'HILL']\n",
        "    }\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    best_metrics = {}\n",
        "    epochs_without_improvement = 0\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    total_batches = len(train_loader)\n",
        "    total_samples = len(train_loader.dataset)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "            batch_start_time = time.time()\n",
        "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
        "\n",
        "            # Warning if data is not transferred to the correct device\n",
        "            if inputs.device.type == 'cpu' or labels.device.type == 'cpu':\n",
        "                print(f\"⚠️ Warning: Inputs or labels still on CPU — inputs: {inputs.device}, labels: {labels.device}\")\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # AMP for faster and memory-efficient training\n",
        "            with autocast(device_type=device):\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            # Gradient scaling + clipping for stability\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "            # Progress monitoring\n",
        "            if batch_idx % 10 == 0 or batch_idx == total_batches - 1:\n",
        "                batch_time = time.time() - batch_start_time\n",
        "                elapsed_time = time.time() - epoch_start_time\n",
        "                percent_complete = (batch_idx + 1) / total_batches * 100\n",
        "                eta = (elapsed_time / (batch_idx + 1)) * (total_batches - batch_idx - 1)\n",
        "\n",
        "                gpu_mem_alloc = torch.cuda.memory_allocated(device) / 1024**2\n",
        "                gpu_mem_max = torch.cuda.max_memory_allocated(device) / 1024**2\n",
        "                cpu_mem = psutil.virtual_memory().used / 1024**2\n",
        "                cpu_percent = psutil.cpu_percent(interval=None)\n",
        "\n",
        "                print(\"\\n\" + \"-\" * 60)\n",
        "                print(f\"Epoch [{epoch+1}/{num_epochs}] | Batch [{batch_idx+1}/{total_batches}] \"\n",
        "                      f\"({percent_complete:.1f}%)\")\n",
        "                print(f\"Loss        : {loss.item():.4f}\")\n",
        "                print(f\"Batch Time  : {batch_time:.2f}s | ETA: {format_time(eta)}\")\n",
        "                print(f\"GPU Memory  : {gpu_mem_alloc:.1f} MB (Max: {gpu_mem_max:.1f} MB)\")\n",
        "                print(f\"CPU Memory  : {cpu_mem:.1f} MB | CPU Usage: {cpu_percent:.1f}%\")\n",
        "                print(\"-\" * 60)\n",
        "\n",
        "        # Epoch-level metrics\n",
        "        epoch_loss = running_loss / total_samples\n",
        "        train_acc = correct_train / total_train\n",
        "        history['train_loss'].append(epoch_loss)\n",
        "\n",
        "        # Evaluate on validation set\n",
        "        val_metrics = evaluate(model, val_loader)\n",
        "        history['val_metrics'].append(val_metrics)\n",
        "\n",
        "        # Scheduler step\n",
        "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "            scheduler.step(val_metrics['accuracy'])\n",
        "        else:\n",
        "            scheduler.step()\n",
        "\n",
        "        # Checkpoint the best model\n",
        "        if val_metrics['accuracy'] > best_val_acc:\n",
        "            best_val_acc = val_metrics['accuracy']\n",
        "            best_metrics = val_metrics\n",
        "            history['best_epoch'] = epoch + 1\n",
        "            epochs_without_improvement = 0\n",
        "\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_metrics': val_metrics,\n",
        "                'train_loss': epoch_loss,\n",
        "                'train_acc': train_acc,\n",
        "            }, checkpoint_path)\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(\"\\n\" + \"=\" * 60)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} Summary\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"Train Loss     : {epoch_loss:.4f}\")\n",
        "        print(f\"Train Accuracy : {train_acc:.4f}\")\n",
        "        print(f\"Val Accuracy   : {val_metrics['accuracy']:.4f}\")\n",
        "        print(f\"Val F1-Macro   : {val_metrics['f1_macro']:.4f}\")\n",
        "        print(f\"Val AUC (OVO)  : {val_metrics['auc_ovo']:.4f}\")\n",
        "        print(f\"Cohen’s Kappa  : {val_metrics['kappa']:.4f}\")\n",
        "        print(\"\\nClassification Report:\\n\")\n",
        "        print(val_metrics['classification_report'])\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Early stopping\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"\\nEarly stopping triggered at epoch {epoch + 1}. \"\n",
        "                  f\"No improvement for {patience} consecutive epochs.\")\n",
        "            break\n",
        "\n",
        "    print(\"\\n\" + \"#\" * 60)\n",
        "    print(f\"Training complete. Best validation at epoch {history['best_epoch']}\")\n",
        "    print(f\"Best Val Accuracy: {best_val_acc:.4f} | F1-Macro: {best_metrics['f1_macro']:.4f}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(best_metrics['confusion_matrix'])\n",
        "    print(\"#\" * 60)\n",
        "\n",
        "    return best_metrics, history\n",
        "\n",
        "\n",
        "# Evaluation Function: Compute performance metrics on validation/test set\n",
        "def evaluate(model, loader, num_classes=4):\n",
        "    model.eval()\n",
        "    all_preds, all_labels, all_probs = [], [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for patches, labels in loader:\n",
        "            patches, labels = patches.to(model.device), labels.to(model.device)\n",
        "            outputs = model(patches)\n",
        "            all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Convert lists to numpy arrays\n",
        "    y_true = np.array(all_labels)\n",
        "    y_pred = np.array(all_preds)\n",
        "    y_probs = np.array(all_probs)\n",
        "\n",
        "    # Compute key metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "    f1_per_class = f1_score(y_true, y_pred, average=None)\n",
        "    precision_macro = precision_score(y_true, y_pred, average='macro')\n",
        "    recall_macro = recall_score(y_true, y_pred, average='macro')\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_probs, multi_class='ovo', average='macro')\n",
        "    except ValueError:\n",
        "        auc = float('nan')  # In case of invalid inputs for AUC\n",
        "\n",
        "    kappa = cohen_kappa_score(y_true, y_pred)\n",
        "    clf_report = classification_report(y_true, y_pred, target_names=['Cover', 'LSB', 'WOW', 'HILL'])\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_per_class': f1_per_class,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'auc_ovo': auc,\n",
        "        'kappa': kappa,\n",
        "        'confusion_matrix': cm,\n",
        "        'classification_report': clf_report\n",
        "    }\n"
      ],
      "metadata": {
        "id": "17HDQNKWThK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization Functions\n"
      ],
      "metadata": {
        "id": "Ahgd3Is9dkA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot Training History Metrics\n",
        "def plot_history_metrics(history_dict):\n",
        "    \"\"\"\n",
        "    Plot training loss, validation accuracy, and F1-Macro over epochs.\n",
        "\n",
        "    Parameters:\n",
        "    - history_dict (dict): Contains 'train_loss' and 'val_metrics' with validation scores.\n",
        "    \"\"\"\n",
        "    train_loss = history_dict.get(\"train_loss\", [])\n",
        "    val_metrics = history_dict.get(\"val_metrics\", [])\n",
        "    val_acc = [m['accuracy'] for m in val_metrics]\n",
        "    val_f1 = [m['f1_macro'] for m in val_metrics]\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "\n",
        "    # Training Loss\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.plot(train_loss, label='Train Loss', color='blue')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Validation Accuracy\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.plot(val_acc, label='Val Accuracy', color='green')\n",
        "    plt.title('Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Validation F1-Macro\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.plot(val_f1, label='Val F1-Macro', color='orange')\n",
        "    plt.title('Validation F1-Macro')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('F1-Macro')\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Confusion Matrix Heatmap\n",
        "def plot_confusion_matrix(cm, class_names, title=\"Confusion Matrix\", output_path=None):\n",
        "    \"\"\"\n",
        "    Plot and optionally save the confusion matrix as a heatmap.\n",
        "\n",
        "    Parameters:\n",
        "    - cm (ndarray): Confusion matrix.\n",
        "    - class_names (list): Names of the classes.\n",
        "    - title (str): Title for the heatmap.\n",
        "    - output_path (str): If provided, saves the figure to this path.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "\n",
        "    if output_path:\n",
        "        plt.savefig(output_path, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "jUgo53Vtd3nR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1: Train Modified Classifier Head Only"
      ],
      "metadata": {
        "id": "NRTshDYaQNKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import GradScaler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "import time\n",
        "\n",
        "# -----------------------------------------------\n",
        "# Phase 1: Partial Fine-Tuning of Pretrained Model\n",
        "# -----------------------------------------------\n",
        "\n",
        "# Freeze all layers\n",
        "for param in model.model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze final block and classifier\n",
        "for param in model.model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "for param in model.model.fc.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Optimizer with different learning rates\n",
        "optimizer = AdamW([\n",
        "    {'params': model.model.layer4.parameters(), 'lr': 3e-5},\n",
        "    {'params': model.model.fc.parameters(), 'lr': 1e-4}\n",
        "], weight_decay=1e-4)\n",
        "\n",
        "# Cosine Annealing LR Scheduler\n",
        "scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=10,       # Maximum number of iterations (usually = num_epochs)\n",
        "    eta_min=1e-6,   # Minimum learning rate\n",
        "    last_epoch=-1   # Start fresh\n",
        ")\n",
        "\n",
        "# Loss Function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Begin Training\n",
        "best_metrics, history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=10,\n",
        "    checkpoint_path='phase1_best_model.pth',\n",
        "    device=device,\n",
        "    patience=7\n",
        ")\n",
        "\n",
        "# Save model state and entire model\n",
        "torch.save(model.state_dict(), 'phase1_model_state_dict.pth')\n",
        "torch.save(model, 'phase1_full_model.pth')"
      ],
      "metadata": {
        "id": "QLmaPu7SUmMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import psutil\n",
        "\n",
        "# Plot Confusion Matrices\n",
        "plot_confusion_matrix(\n",
        "    best_metrics['confusion_matrix'],\n",
        "    class_names=['Cover', 'LSB', 'WOW', 'HILL'],\n",
        "    title='Validation Confusion Matrix',\n",
        "    output_path='/content/drive/MyDrive/Stego-Images-Dataset/phase1_cm.png'\n",
        ")\n",
        "plot_history_metrics(history)"
      ],
      "metadata": {
        "id": "APZjSsRJ4qfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2: Add SRM + HighFreqPath\n"
      ],
      "metadata": {
        "id": "htd26NUeQWH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# SRM Layer: Extracts spatial residuals via fixed filters\n",
        "# ------------------------------------------------------\n",
        "class SRMLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    SRMLayer applies 3 fixed high-pass filters to grayscale input:\n",
        "    - Laplacian (noise detection)\n",
        "    - Gabor (directional inconsistencies)\n",
        "    - Hybrid edge detector\n",
        "\n",
        "    Input: (B, 1, H, W)\n",
        "    Output: (B, 3, H, W)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.srm = nn.Conv2d(1, 3, kernel_size=5, padding=2, bias=False)\n",
        "\n",
        "        # Define SRM filter kernels\n",
        "        kernel1 = torch.tensor([\n",
        "            [-1, -1, -1, -1, -1],\n",
        "            [-1, -1, -1, -1, -1],\n",
        "            [-1, -1, 24, -1, -1],\n",
        "            [-1, -1, -1, -1, -1],\n",
        "            [-1, -1, -1, -1, -1]\n",
        "        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        kernel2 = torch.tensor([\n",
        "            [ 0,  0, -1,  0,  0],\n",
        "            [ 0, -1,  0,  1,  0],\n",
        "            [-1,  0,  6,  0, -1],\n",
        "            [ 0,  1,  0, -1,  0],\n",
        "            [ 0,  0, -1,  0,  0]\n",
        "        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        kernel3 = torch.tensor([\n",
        "            [ 0,  0, -1,  0,  0],\n",
        "            [ 0,  0, -1,  0,  0],\n",
        "            [-1, -1, 12, -1, -1],\n",
        "            [ 0,  0, -1,  0,  0],\n",
        "            [ 0,  0, -1,  0,  0]\n",
        "        ], dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "        # Normalize kernels\n",
        "        kernel1 /= kernel1.sum()\n",
        "        kernel2 /= kernel2.sum()\n",
        "        kernel3 /= kernel3.sum()\n",
        "\n",
        "        # Assign to weights and freeze\n",
        "        self.srm.weight.data = torch.cat([kernel1, kernel2, kernel3], dim=0)\n",
        "        self.srm.requires_grad_(False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.srm(x)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# High-Frequency Path: Trainable branch for high-pass cues\n",
        "# ------------------------------------------------------\n",
        "class HighFreqPath(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple 2-layer CNN branch to extract learnable high-frequency features.\n",
        "\n",
        "    Input: (B, 1, H, W)\n",
        "    Output: (B, 32, H, W)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        return torch.relu(self.conv2(x))\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Full Model: SRM + High-Frequency Path + ResNet34 backbone\n",
        "# ------------------------------------------------------\n",
        "class StegoResNet34(nn.Module):\n",
        "    def __init__(self, pretrained_model):\n",
        "        \"\"\"\n",
        "        - Combines SRM features, learnable high-frequency features, and a ResNet34 backbone.\n",
        "        - Final classifier uses both ResNet + high-frequency features.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.srm_layer = SRMLayer()\n",
        "        self.high_freq_path = HighFreqPath()\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.high_freq_reduce = nn.Conv2d(32, 2, kernel_size=1)\n",
        "\n",
        "        # Load base model (handle LogitScaler-wrapped case)\n",
        "        self.model = pretrained_model.model if hasattr(pretrained_model, 'model') else pretrained_model\n",
        "\n",
        "        # Modify first conv layer to accept 5 channels (3 SRM + 2 reduced HF)\n",
        "        self.model.conv1 = nn.Conv2d(5, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "\n",
        "        # Custom classifier head\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 + 32 * 7 * 7, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.8),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 4)  # For 4-class classification\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        srm_out = self.srm_layer(x)                           # (B, 3, H, W)\n",
        "        high_freq_out = self.high_freq_path(x)                # (B, 32, H, W)\n",
        "        reduced_high_freq = self.high_freq_reduce(high_freq_out)  # (B, 2, H, W)\n",
        "\n",
        "        combined_input = torch.cat([srm_out, reduced_high_freq], dim=1)  # (B, 5, H, W)\n",
        "\n",
        "        # Pass through modified ResNet\n",
        "        x = self.model.conv1(combined_input)\n",
        "        x = self.model.bn1(x)\n",
        "        x = self.model.relu(x)\n",
        "        x = self.model.maxpool(x)\n",
        "        x = self.model.layer1(x)\n",
        "        x = self.model.layer2(x)\n",
        "        x = self.model.layer3(x)\n",
        "        x = self.model.layer4(x)\n",
        "        x = self.model.avgpool(x)\n",
        "        resnet_features = torch.flatten(x, 1)                 # (B, 512)\n",
        "\n",
        "        # Pool and flatten high-frequency branch\n",
        "        hf_flat = self.adaptive_pool(high_freq_out).view(x.size(0), -1)  # (B, 1568)\n",
        "\n",
        "        combined = torch.cat([resnet_features, hf_flat], dim=1)          # (B, 2080)\n",
        "        return self.fc(combined)\n",
        "\n",
        "# ------------------------------------------------------\n",
        "# Focal Loss: Class imbalance-aware alternative to CE\n",
        "# ------------------------------------------------------\n",
        "class FocalLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Focal Loss = (1 - pt)^gamma * CrossEntropy\n",
        "    Helps focus training on harder samples.\n",
        "\n",
        "    Args:\n",
        "        alpha (Tensor): class-wise weights\n",
        "        gamma (float): focusing parameter\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=None, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal = (1 - pt) ** self.gamma * ce_loss\n",
        "        return focal.mean()\n"
      ],
      "metadata": {
        "id": "NmEKoFHMiy2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First recreate the Phase 1 architecture\n",
        "def phase1_model():\n",
        "    # Load a base ResNet34 with no pretrained weights\n",
        "    model = models.resnet34(weights=None)\n",
        "\n",
        "    # Modify the input layer to accept grayscale images (1 channel)\n",
        "    model.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=64,\n",
        "            kernel_size=7,\n",
        "            stride=2,\n",
        "            padding=3,\n",
        "            bias=False\n",
        "        )\n",
        "\n",
        "    # Redefine the classifier head with dropout, batchnorm, and LeakyReLU\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(0.5),  # Strong regularization\n",
        "        nn.Linear(model.fc.in_features, 256),\n",
        "        nn.BatchNorm1d(256),\n",
        "        nn.LeakyReLU(0.1, inplace=True),\n",
        "        nn.Dropout(0.3),  # Additional regularization\n",
        "        nn.Linear(256, num_classes, bias=False)\n",
        "    )\n",
        "\n",
        "    return LogitScaler(model)\n",
        "\n",
        "# Load Phase 1 model\n",
        "phase1_model = phase1_model().to(device)\n",
        "checkpoint = torch.load('phase1_best_model.pth', map_location=device, weights_only=False)\n",
        "phase1_model.load_state_dict(checkpoint['model_state_dict'])  # Load pretrained weights from Phase 1\n",
        "\n",
        "# Convert to Phase 2 architecture\n",
        "model = StegoResNet34(phase1_model).to(device)  # Wrap Phase 1 backbone in custom Phase 2 model\n",
        "\n",
        "# Reinitialize conv1 for 5-channel input (3 from SRM + 2 from HighFreq)\n",
        "nn.init.kaiming_normal_(model.model.conv1.weight, mode='fan_out', nonlinearity='relu')\n",
        "\n",
        "# Freezing all layers initially\n",
        "for name, param in model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Unfreeze only the SRM layer, high-frequency path, and classifier head for Phase 2 fine-tuning\n",
        "for name, param in model.model.fc.named_parameters():\n",
        "    param.requires_grad = True\n",
        "for name, param in model.srm_layer.named_parameters():\n",
        "    param.requires_grad = True\n",
        "for name, param in model.high_freq_path.named_parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Optimizer with adjusted learning rates for different submodules\n",
        "optimizer = optim.AdamW([\n",
        "    {'params': model.srm_layer.parameters(), 'lr': 1e-4},          # SRM filters (static, but learnable in Phase 2)\n",
        "    {'params': model.high_freq_path.parameters(), 'lr': 1e-4},    # High frequency path\n",
        "    {'params': model.model.fc.parameters(), 'lr': 5e-5}            # Classifier head\n",
        "], weight_decay=1e-3)  # Weight decay for regularization\n",
        "\n",
        "# Initialize new layers with Xavier initialization for stability\n",
        "def init_srm(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        nn.init.xavier_uniform_(m.weight, gain=nn.init.calculate_gain('leaky_relu', 0.1))\n",
        "\n",
        "# Apply initializer to custom submodules\n",
        "model.srm_layer.apply(init_srm)\n",
        "model.high_freq_path.apply(init_srm)\n",
        "\n",
        "# Cosine annealing scheduler for dynamic learning rate decay\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6, last_epoch=-1)\n",
        "\n",
        "# Define weighted Focal Loss to handle class imbalance\n",
        "class_weights = torch.tensor([0.30, 0.30, 0.20, 0.20]).to(device)\n",
        "criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "\n",
        "# Start training Phase 2 model\n",
        "best_metrics, history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    num_epochs=20,\n",
        "    checkpoint_path='phase2_best_model.pth',  # Save best checkpoint\n",
        "    device=device,\n",
        "    patience=7  # Early stopping\n",
        ")\n",
        "\n",
        "# Save final model weights and architecture\n",
        "torch.save(model.state_dict(), 'full_model_state_dict.pth')\n",
        "torch.save(model, 'full_model.pth')\n"
      ],
      "metadata": {
        "id": "8t__IfPzjUMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Confusion Matrices\n",
        "plot_confusion_matrix(\n",
        "    best_metrics['confusion_matrix'],\n",
        "    class_names=['Cover', 'LSB', 'WOW', 'HILL'],\n",
        "    title='Validation Confusion Matrix',\n",
        "    output_path='/content/drive/MyDrive/Stego-Images-Dataset/phase2_cm.png'\n",
        ")\n",
        "plot_history_metrics(history)"
      ],
      "metadata": {
        "id": "qu-7408WsvmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "wpqJjB0ywaVV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.load('full_model.pth', map_location=device)\n",
        "model.eval()\n",
        "\n",
        "# Evaluate model\n",
        "metrics = evaluate(model, test_loader, num_classes=4)\n",
        "\n",
        "# results\n",
        "print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "print(f\"F1 Macro: {metrics['f1_macro']:.4f}\")\n",
        "print(f\"Precision Macro: {metrics['precision_macro']:.4f}\")\n",
        "print(f\"Recall Macro: {metrics['recall_macro']:.4f}\")\n",
        "print(f\"AUC (OVO): {metrics['auc_ovo']:.4f}\")\n",
        "print(f\"Cohen's Kappa: {metrics['kappa']:.4f}\")\n",
        "print(\"\\nF1 Score per Class:\", metrics['f1_per_class'])\n",
        "print(\"\\nConfusion Matrix:\\n\", metrics['confusion_matrix'])\n",
        "print(\"\\nClassification Report:\\n\", metrics['classification_report'])"
      ],
      "metadata": {
        "id": "tqtX22sDyJuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}